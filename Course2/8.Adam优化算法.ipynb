{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ffc539-14f2-49e4-86c7-a5c8ad0f09ad",
   "metadata": {},
   "source": [
    "### Adam优化算法\n",
    "Adam优化算法实际上就是将RMSprop和Momentum结合在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22733ba-21c8-470f-b0c6-e53d4ad2b43a",
   "metadata": {},
   "source": [
    "实现步骤：\n",
    "\n",
    "- 初始化：$V_{dw}=0,S_{dw}=0,V_{db}=0,S_{db}=0$\n",
    "\n",
    "- On iteration t:\n",
    "    - Compute $dw,db$ using current mini-batch\n",
    "      \n",
    "    - $V_{dw}=\\beta _1 V_{dw}+(1-\\beta_1)dw$\n",
    "    - $V_{db}=\\beta _1 V_{db}+(1-\\beta_1)db$\n",
    "\n",
    "    - $S_{dw}=\\beta_2 S_{dw}+(1-\\beta_2)(dw)^2$\n",
    "    - $S_{db}=\\beta_2 S_{db}+(1-\\beta_2)(db)^2$\n",
    " \n",
    "    - $V^{corrected}_{dw}=V_{dw}/(1-\\beta _1^t)$\n",
    "    - $V^{corrected}_{db}=V_{db}/(1-\\beta_1 ^t)$\n",
    "\n",
    "    - $S^{corrected}_{dw}=S_{dw}/(1-\\beta _2^t)$\n",
    "    - $S^{corrected}_{db}=S_{db}/(1-\\beta_2 ^t)$\n",
    "\n",
    "    - $w:=w-\\alpha \\frac{V^{corrected}_{dw}}{\\sqrt{S^{corrected}_{dw}}+\\epsilon}$\n",
    "    - $b:=b-\\alpha \\frac{V^{corrected}_{db}}{\\sqrt{S^{corrected}_{db}}+\\epsilon}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87244f2a-c36e-422c-a039-11977c1eb34f",
   "metadata": {},
   "source": [
    "Adam算法涉及很多超参数：\n",
    "\n",
    "$\\alpha$：学习率，需要自行尝试得到合适的值。  \n",
    "$\\beta_1$ ：常用的值是0.9。  \n",
    "$\\beta_2$：Adam算法的发明者推荐使用0.999。  \n",
    "$\\epsilon$：Adam算法的发明者建议为$10^{-8}$ 。  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
